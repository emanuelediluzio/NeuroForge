# Backend Configuration

# PATH TO YOUR LOCAL MODEL
# Example: "/Users/username/models/llama-3-8b-instruct.Q4_K_M.gguf"
# or a Hugging Face ID if you want to download it: "meta-llama/Meta-Llama-3-8B-Instruct"
ORCHESTRATOR_MODEL_PATH = "MOCK_MODE" 

# If MOCK_MODE, the system will simulate responses.
# If you put a real path, ensure you have the necessary libraries installed.
